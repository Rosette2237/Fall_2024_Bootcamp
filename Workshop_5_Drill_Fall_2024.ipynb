{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ad6a03d49ec143b1b624029bcb0fb5b6",
    "deepnote_cell_height": 156.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Workshop 5 Drill\n",
    "This drill aims to give you an opportunity to practice deep learning on an interesting problem. \n",
    "\n",
    "For this drill, we will use PyTorch to build our deep learning architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dbe79475c1084a3a8c8812c392f67696",
    "deepnote_cell_height": 181.1875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## What are we solving today?\n",
    "For this drill, we will be using the Fashion MNIST dataset to classify fashion images. \n",
    "\n",
    "Link for more information: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "This dataset is a classic dataset that is used to benchmark deep architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "f401c72fde6f461c911211e49110a457",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1653,
    "execution_start": 1658284349460,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "2a8ef4c4d9f94471b428ffe71f88ccaf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1658284351119,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your python files imported\n",
    "import load_dataset\n",
    "import model\n",
    "import trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fd0346dc1c834547886544e4e518ce6f",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Step 1: Load in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "47be3b270e374757b81549719bc38355",
    "deepnote_cell_height": 97.1875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Before we can do anything, we need to be able to load in the Fashion MNIST dataset. Luckily, the `datasets` library within the `torchvision` package contains the Fashion MNIST dataset. Load in both the train and test datasets. You also are able to specify the transformation to apply to both the train and test sets. Fill out the `load_dataset.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "f3b9c0d9613a4097aca12de02bf6da06",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1658691667566,
    "owner_user_id": "c4ff6b27-0006-4cbe-ae70-75fa43507858",
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Test that your implementation from load_dataset.py works\n",
    "trainloader, testloader = load_dataset.load_fashion_mnist()\n",
    "\n",
    "# Examine a sample\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "9e993793cab84b3085720eccbfb0d68e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 208,
    "execution_start": 1658284351216,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2450dab4d40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3521fa72ce54873af9eb32dcde5df27",
    "deepnote_cell_height": 585.96875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Step 2: Build the Model\n",
    "Now that we are able to load in the Fashion MNIST as torch Dataloaders, we get to the fun part!\n",
    "\n",
    "We can now construct a deep learning model that can be used to classify images of fashion objects. \n",
    "\n",
    "In `model.py`, you will build the architecture shown below (in the `MyBasicModel` class). Convolutional Neural Networks are very popular for image classification \n",
    "![Fashion MNIST Image](dl_arch.PNG) (Credit: https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0fa1d881ee4342c490e6501a0cbd4144",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Hint: Linear layers might be helpful for you to build the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "5c00661732b0489aa75ffddae05899af",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1658284351426,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyBasicModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Test Basic model\n",
    "import model\n",
    "basic_model = model.MyBasicModel()\n",
    "print(repr(basic_model)) #check that your architecture matches up to the diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d6b9d7ea53764718bd99c9554fd60979",
    "deepnote_cell_height": 46,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "799536c703934c9a8c9f3b2034974cf7",
    "deepnote_cell_height": 209.578125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Step 3: Train the model\n",
    "Use `trainer.py` to fill in the function to train your deep learning model. You will need to configure the following:\n",
    "\n",
    "* Loss Function: CELoss\n",
    "* Optimizer: Adam\n",
    "* Epoch count: 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "658c172a59fc4344a39e6eceed93945d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1658284351432,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use Pytorch to configure the loss function, optimizer, epoch count\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() # CELoss\n",
    "optimizer = optim.Adam(basic_model.parameters(), lr=1e-3)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "d403be17bb0f4af8a65aaead85764da5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 214083,
    "execution_start": 1658284351478,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss: 659.7352861464024\n",
      "Test loss: 83.20292422175407\n",
      "Train Accuracy: 73.42999999999999\n",
      "Test Accuracy: 79.58\n",
      "Epoch: 1\n",
      "Train loss: 437.8924125880003\n",
      "Test loss: 68.57513973116875\n",
      "Train Accuracy: 82.78166666666667\n",
      "Test Accuracy: 84.73\n",
      "Epoch: 2\n",
      "Train loss: 378.74756260216236\n",
      "Test loss: 63.38403418660164\n",
      "Train Accuracy: 85.16333333333334\n",
      "Test Accuracy: 85.48\n",
      "Epoch: 3\n",
      "Train loss: 339.58463798463345\n",
      "Test loss: 61.42665381729603\n",
      "Train Accuracy: 86.80166666666666\n",
      "Test Accuracy: 85.38\n",
      "Epoch: 4\n",
      "Train loss: 321.36191253364086\n",
      "Test loss: 56.770705699920654\n",
      "Train Accuracy: 87.395\n",
      "Test Accuracy: 86.69\n",
      "Epoch: 5\n",
      "Train loss: 302.5765891894698\n",
      "Test loss: 55.83265545964241\n",
      "Train Accuracy: 88.05166666666666\n",
      "Test Accuracy: 86.83\n",
      "Epoch: 6\n",
      "Train loss: 289.51449420303106\n",
      "Test loss: 55.32146781682968\n",
      "Train Accuracy: 88.51666666666667\n",
      "Test Accuracy: 87.16000000000001\n",
      "Epoch: 7\n",
      "Train loss: 276.97971181571484\n",
      "Test loss: 51.94788944721222\n",
      "Train Accuracy: 89.06833333333334\n",
      "Test Accuracy: 87.66000000000001\n",
      "Epoch: 8\n",
      "Train loss: 267.885514318943\n",
      "Test loss: 49.823908157646656\n",
      "Train Accuracy: 89.33833333333332\n",
      "Test Accuracy: 88.18\n",
      "Epoch: 9\n",
      "Train loss: 258.79834796488285\n",
      "Test loss: 51.52923735976219\n",
      "Train Accuracy: 89.66666666666666\n",
      "Test Accuracy: 88.14\n",
      "Epoch: 10\n",
      "Train loss: 249.12413833290339\n",
      "Test loss: 48.960657216608524\n",
      "Train Accuracy: 90.12166666666667\n",
      "Test Accuracy: 88.83\n",
      "Epoch: 11\n",
      "Train loss: 241.40740954875946\n",
      "Test loss: 48.17776009440422\n",
      "Train Accuracy: 90.37833333333334\n",
      "Test Accuracy: 88.8\n",
      "Epoch: 12\n",
      "Train loss: 234.17310653999448\n",
      "Test loss: 48.61282820999622\n",
      "Train Accuracy: 90.53666666666666\n",
      "Test Accuracy: 88.75\n",
      "Epoch: 13\n",
      "Train loss: 227.0492989346385\n",
      "Test loss: 48.720847234129906\n",
      "Train Accuracy: 90.86333333333333\n",
      "Test Accuracy: 88.39\n",
      "Epoch: 14\n",
      "Train loss: 221.528473906219\n",
      "Test loss: 47.917082257568836\n",
      "Train Accuracy: 91.23666666666666\n",
      "Test Accuracy: 88.98\n",
      "Epoch: 15\n",
      "Train loss: 215.85102279484272\n",
      "Test loss: 47.12436884641647\n",
      "Train Accuracy: 91.33666666666667\n",
      "Test Accuracy: 89.12\n",
      "Epoch: 16\n",
      "Train loss: 206.90826473385096\n",
      "Test loss: 46.49844016879797\n",
      "Train Accuracy: 91.79\n",
      "Test Accuracy: 88.99000000000001\n",
      "Epoch: 17\n",
      "Train loss: 203.01202422380447\n",
      "Test loss: 49.26714193075895\n",
      "Train Accuracy: 91.77333333333333\n",
      "Test Accuracy: 88.7\n",
      "Epoch: 18\n",
      "Train loss: 198.08620107918978\n",
      "Test loss: 47.29645907878876\n",
      "Train Accuracy: 92.04833333333333\n",
      "Test Accuracy: 89.39\n",
      "Epoch: 19\n",
      "Train loss: 192.35012432932854\n",
      "Test loss: 48.74043373018503\n",
      "Train Accuracy: 92.22\n",
      "Test Accuracy: 89.02\n",
      "Epoch: 20\n",
      "Train loss: 186.47141272202134\n",
      "Test loss: 47.73895820975304\n",
      "Train Accuracy: 92.41166666666668\n",
      "Test Accuracy: 89.14999999999999\n",
      "Epoch: 21\n",
      "Train loss: 180.4032496958971\n",
      "Test loss: 47.443223148584366\n",
      "Train Accuracy: 92.83\n",
      "Test Accuracy: 89.62\n",
      "Epoch: 22\n",
      "Train loss: 178.86316156759858\n",
      "Test loss: 48.13251793384552\n",
      "Train Accuracy: 92.81\n",
      "Test Accuracy: 89.08\n",
      "Epoch: 23\n",
      "Train loss: 172.8761522769928\n",
      "Test loss: 52.92041778564453\n",
      "Train Accuracy: 92.95166666666667\n",
      "Test Accuracy: 88.8\n",
      "Epoch: 24\n",
      "Train loss: 170.9907287582755\n",
      "Test loss: 49.85493303090334\n",
      "Train Accuracy: 93.15666666666667\n",
      "Test Accuracy: 89.3\n",
      "Epoch: 25\n",
      "Train loss: 164.74730700999498\n",
      "Test loss: 52.78001829236746\n",
      "Train Accuracy: 93.36833333333333\n",
      "Test Accuracy: 89.0\n",
      "Epoch: 26\n",
      "Train loss: 162.14337189123034\n",
      "Test loss: 53.239639073610306\n",
      "Train Accuracy: 93.39333333333333\n",
      "Test Accuracy: 89.02\n",
      "Epoch: 27\n",
      "Train loss: 157.5553662031889\n",
      "Test loss: 51.18641225993633\n",
      "Train Accuracy: 93.64666666666666\n",
      "Test Accuracy: 89.5\n",
      "Epoch: 28\n",
      "Train loss: 152.87753115408123\n",
      "Test loss: 51.28037444502115\n",
      "Train Accuracy: 93.79833333333333\n",
      "Test Accuracy: 89.31\n",
      "Epoch: 29\n",
      "Train loss: 148.3325045509264\n",
      "Test loss: 56.41432575508952\n",
      "Train Accuracy: 93.955\n",
      "Test Accuracy: 88.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [659.7352861464024,\n",
       "  437.8924125880003,\n",
       "  378.74756260216236,\n",
       "  339.58463798463345,\n",
       "  321.36191253364086,\n",
       "  302.5765891894698,\n",
       "  289.51449420303106,\n",
       "  276.97971181571484,\n",
       "  267.885514318943,\n",
       "  258.79834796488285,\n",
       "  249.12413833290339,\n",
       "  241.40740954875946,\n",
       "  234.17310653999448,\n",
       "  227.0492989346385,\n",
       "  221.528473906219,\n",
       "  215.85102279484272,\n",
       "  206.90826473385096,\n",
       "  203.01202422380447,\n",
       "  198.08620107918978,\n",
       "  192.35012432932854,\n",
       "  186.47141272202134,\n",
       "  180.4032496958971,\n",
       "  178.86316156759858,\n",
       "  172.8761522769928,\n",
       "  170.9907287582755,\n",
       "  164.74730700999498,\n",
       "  162.14337189123034,\n",
       "  157.5553662031889,\n",
       "  152.87753115408123,\n",
       "  148.3325045509264],\n",
       " 'test_loss': [83.20292422175407,\n",
       "  68.57513973116875,\n",
       "  63.38403418660164,\n",
       "  61.42665381729603,\n",
       "  56.770705699920654,\n",
       "  55.83265545964241,\n",
       "  55.32146781682968,\n",
       "  51.94788944721222,\n",
       "  49.823908157646656,\n",
       "  51.52923735976219,\n",
       "  48.960657216608524,\n",
       "  48.17776009440422,\n",
       "  48.61282820999622,\n",
       "  48.720847234129906,\n",
       "  47.917082257568836,\n",
       "  47.12436884641647,\n",
       "  46.49844016879797,\n",
       "  49.26714193075895,\n",
       "  47.29645907878876,\n",
       "  48.74043373018503,\n",
       "  47.73895820975304,\n",
       "  47.443223148584366,\n",
       "  48.13251793384552,\n",
       "  52.92041778564453,\n",
       "  49.85493303090334,\n",
       "  52.78001829236746,\n",
       "  53.239639073610306,\n",
       "  51.18641225993633,\n",
       "  51.28037444502115,\n",
       "  56.41432575508952],\n",
       " 'train_accuracy': [73.42999999999999,\n",
       "  82.78166666666667,\n",
       "  85.16333333333334,\n",
       "  86.80166666666666,\n",
       "  87.395,\n",
       "  88.05166666666666,\n",
       "  88.51666666666667,\n",
       "  89.06833333333334,\n",
       "  89.33833333333332,\n",
       "  89.66666666666666,\n",
       "  90.12166666666667,\n",
       "  90.37833333333334,\n",
       "  90.53666666666666,\n",
       "  90.86333333333333,\n",
       "  91.23666666666666,\n",
       "  91.33666666666667,\n",
       "  91.79,\n",
       "  91.77333333333333,\n",
       "  92.04833333333333,\n",
       "  92.22,\n",
       "  92.41166666666668,\n",
       "  92.83,\n",
       "  92.81,\n",
       "  92.95166666666667,\n",
       "  93.15666666666667,\n",
       "  93.36833333333333,\n",
       "  93.39333333333333,\n",
       "  93.64666666666666,\n",
       "  93.79833333333333,\n",
       "  93.955],\n",
       " 'test_accuracy': [79.58,\n",
       "  84.73,\n",
       "  85.48,\n",
       "  85.38,\n",
       "  86.69,\n",
       "  86.83,\n",
       "  87.16000000000001,\n",
       "  87.66000000000001,\n",
       "  88.18,\n",
       "  88.14,\n",
       "  88.83,\n",
       "  88.8,\n",
       "  88.75,\n",
       "  88.39,\n",
       "  88.98,\n",
       "  89.12,\n",
       "  88.99000000000001,\n",
       "  88.7,\n",
       "  89.39,\n",
       "  89.02,\n",
       "  89.14999999999999,\n",
       "  89.62,\n",
       "  89.08,\n",
       "  88.8,\n",
       "  89.3,\n",
       "  89.0,\n",
       "  89.02,\n",
       "  89.5,\n",
       "  89.31,\n",
       "  88.74]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.run_dl_model(trainloader, testloader, basic_model, optimizer,loss_function, epochs)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ca24fa5910b1482880db1884e6b90a5a",
    "deepnote_cell_height": 571.09375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Step 4: Having even more fun!\n",
    "So, I gave you one of many possible CNN architectures to train your Fashion MNIST classifier. Another architecture you can try is a pretrained DL architecture called ResNet (Residual Neural Network). The key building block in ResNet is what's called a Basic Block. Below is an comparison of ResNet architecturse (which is what you will use in this exercise):\n",
    "![Resnet](resnet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dc1527ae786748afbae67acf5c9b8817",
    "deepnote_cell_height": 290.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "For this part of the exercise, you will be using Resnet 50 architecture. However, you don't have to build it from scratch. Pytorch allows you to import a pretrained version of the architecture for your use. \n",
    "\n",
    "Check out: https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html#torchvision.models.resnet50\n",
    "\n",
    "We can't just import resnet 50 and we're good. We have to tweak ResNet a bit for Fashion MNIST. Below are the fixes you should make:\n",
    "\n",
    "* The Fashion MNIST uses gray-scale images, so you should take the `conv1` layer in resnet-50 and set `in_channels=1`\n",
    "\n",
    "* The last layer in Resnet-50 is a fully connected layer (ie: `Linear` layer). We want to fix the last `Linear` layer in ResNet such that the output is a `1x10` vector (so you need to worry about `out_features` for the last `Linear` layer). \n",
    "\n",
    "Implement Resnet-50 for Fashion MNIST in `model.py` under the `FashionResNet50` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b611c195d2584319b9a99e800f452f6f",
    "deepnote_cell_height": 46,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "ce36183ddb1844909e721627f2f38c69",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 224,
    "execution_start": 1658691655767,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesse\\anaconda3\\envs\\PYTORCH\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jesse\\anaconda3\\envs\\PYTORCH\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionResNet50(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#check your resnet architecture\n",
    "resnet_model = model.FashionResNet50()\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "2094e07baf2f48238340e378ec830280",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1658285001130,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function: cross‑entropy\n",
    "resnet_loss_function = nn.CrossEntropyLoss()\n",
    "# Optimizer: Adam (attach to the ResNet’s parameters)\n",
    "resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=1e-3)\n",
    "# Number of training epochs\n",
    "resnet_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "bd15be58630b4dd68305b88de6ef6e97",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 640981,
    "execution_start": 1658285003239,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss: 539.4105661511421\n",
      "Test loss: 74.31425428390503\n",
      "Train Accuracy: 80.10833333333333\n",
      "Test Accuracy: 82.61\n",
      "Epoch: 1\n",
      "Train loss: 338.91578683257103\n",
      "Test loss: 55.85645855218172\n",
      "Train Accuracy: 86.75166666666667\n",
      "Test Accuracy: 86.92\n",
      "Epoch: 2\n",
      "Train loss: 306.1775109991431\n",
      "Test loss: 50.78810288012028\n",
      "Train Accuracy: 88.285\n",
      "Test Accuracy: 88.13\n",
      "Epoch: 3\n",
      "Train loss: 318.460780993104\n",
      "Test loss: 48.93907452374697\n",
      "Train Accuracy: 88.43833333333333\n",
      "Test Accuracy: 88.71\n",
      "Epoch: 4\n",
      "Train loss: 282.0658318474889\n",
      "Test loss: 121.8038381934166\n",
      "Train Accuracy: 89.39166666666667\n",
      "Test Accuracy: 76.57000000000001\n",
      "Epoch: 5\n",
      "Train loss: 302.57160123437643\n",
      "Test loss: 47.889462150633335\n",
      "Train Accuracy: 88.45333333333333\n",
      "Test Accuracy: 88.75\n",
      "Epoch: 6\n",
      "Train loss: 256.23175342381\n",
      "Test loss: 43.95853876322508\n",
      "Train Accuracy: 89.98166666666667\n",
      "Test Accuracy: 89.72\n",
      "Epoch: 7\n",
      "Train loss: 226.58194891363382\n",
      "Test loss: 45.37250925600529\n",
      "Train Accuracy: 91.29166666666667\n",
      "Test Accuracy: 89.42\n",
      "Epoch: 8\n",
      "Train loss: 209.87654873728752\n",
      "Test loss: 42.174229480326176\n",
      "Train Accuracy: 91.685\n",
      "Test Accuracy: 90.25999999999999\n",
      "Epoch: 9\n",
      "Train loss: 222.37350045889616\n",
      "Test loss: 48.53823448717594\n",
      "Train Accuracy: 91.42\n",
      "Test Accuracy: 88.77000000000001\n",
      "Epoch: 10\n",
      "Train loss: 280.87301760166883\n",
      "Test loss: 69.85238799452782\n",
      "Train Accuracy: 89.8\n",
      "Test Accuracy: 83.73\n",
      "Epoch: 11\n",
      "Train loss: 286.1895728483796\n",
      "Test loss: 45.52999860048294\n",
      "Train Accuracy: 88.81666666666666\n",
      "Test Accuracy: 89.73\n",
      "Epoch: 12\n",
      "Train loss: 213.66230712085962\n",
      "Test loss: 42.21219501644373\n",
      "Train Accuracy: 91.59\n",
      "Test Accuracy: 90.36\n",
      "Epoch: 13\n",
      "Train loss: 273.8707827106118\n",
      "Test loss: 46.21113395690918\n",
      "Train Accuracy: 90.39500000000001\n",
      "Test Accuracy: 89.11\n",
      "Epoch: 14\n",
      "Train loss: 285.22735967487097\n",
      "Test loss: 43.42906827479601\n",
      "Train Accuracy: 88.98833333333333\n",
      "Test Accuracy: 89.79\n",
      "Epoch: 15\n",
      "Train loss: 223.3418390788138\n",
      "Test loss: 44.28614668548107\n",
      "Train Accuracy: 91.36833333333333\n",
      "Test Accuracy: 89.92999999999999\n",
      "Epoch: 16\n",
      "Train loss: 196.87057239934802\n",
      "Test loss: 40.69530634582043\n",
      "Train Accuracy: 92.38499999999999\n",
      "Test Accuracy: 90.99000000000001\n",
      "Epoch: 17\n",
      "Train loss: 174.85017730668187\n",
      "Test loss: 42.30843772739172\n",
      "Train Accuracy: 93.11666666666667\n",
      "Test Accuracy: 90.55\n",
      "Epoch: 18\n",
      "Train loss: 195.0888720843941\n",
      "Test loss: 43.56898867338896\n",
      "Train Accuracy: 92.54833333333333\n",
      "Test Accuracy: 90.11\n",
      "Epoch: 19\n",
      "Train loss: 170.71103305742145\n",
      "Test loss: 42.658156000077724\n",
      "Train Accuracy: 93.08999999999999\n",
      "Test Accuracy: 90.67\n",
      "Epoch: 20\n",
      "Train loss: 148.01177853904665\n",
      "Test loss: 38.679468624293804\n",
      "Train Accuracy: 94.11\n",
      "Test Accuracy: 90.99000000000001\n",
      "Epoch: 21\n",
      "Train loss: 139.06694577261806\n",
      "Test loss: 40.49032638221979\n",
      "Train Accuracy: 94.36666666666666\n",
      "Test Accuracy: 91.14999999999999\n",
      "Epoch: 22\n",
      "Train loss: 127.60723769105971\n",
      "Test loss: 44.5439650118351\n",
      "Train Accuracy: 94.845\n",
      "Test Accuracy: 90.75\n",
      "Epoch: 23\n",
      "Train loss: 118.4081218354404\n",
      "Test loss: 43.132219702005386\n",
      "Train Accuracy: 95.17333333333333\n",
      "Test Accuracy: 90.57\n",
      "Epoch: 24\n",
      "Train loss: 109.7984828390181\n",
      "Test loss: 48.18362686783075\n",
      "Train Accuracy: 95.555\n",
      "Test Accuracy: 90.63\n",
      "Epoch: 25\n",
      "Train loss: 112.96497997175902\n",
      "Test loss: 42.61178895831108\n",
      "Train Accuracy: 95.69\n",
      "Test Accuracy: 91.24\n",
      "Epoch: 26\n",
      "Train loss: 90.35677300393581\n",
      "Test loss: 44.79326942563057\n",
      "Train Accuracy: 96.41833333333332\n",
      "Test Accuracy: 91.39\n",
      "Epoch: 27\n",
      "Train loss: 104.55255057383329\n",
      "Test loss: 46.90752314776182\n",
      "Train Accuracy: 95.96833333333333\n",
      "Test Accuracy: 90.74\n",
      "Epoch: 28\n",
      "Train loss: 88.36987936962396\n",
      "Test loss: 47.36696935072541\n",
      "Train Accuracy: 96.575\n",
      "Test Accuracy: 91.58\n",
      "Epoch: 29\n",
      "Train loss: 71.06509739160538\n",
      "Test loss: 51.72065329551697\n",
      "Train Accuracy: 97.20166666666667\n",
      "Test Accuracy: 90.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [539.4105661511421,\n",
       "  338.91578683257103,\n",
       "  306.1775109991431,\n",
       "  318.460780993104,\n",
       "  282.0658318474889,\n",
       "  302.57160123437643,\n",
       "  256.23175342381,\n",
       "  226.58194891363382,\n",
       "  209.87654873728752,\n",
       "  222.37350045889616,\n",
       "  280.87301760166883,\n",
       "  286.1895728483796,\n",
       "  213.66230712085962,\n",
       "  273.8707827106118,\n",
       "  285.22735967487097,\n",
       "  223.3418390788138,\n",
       "  196.87057239934802,\n",
       "  174.85017730668187,\n",
       "  195.0888720843941,\n",
       "  170.71103305742145,\n",
       "  148.01177853904665,\n",
       "  139.06694577261806,\n",
       "  127.60723769105971,\n",
       "  118.4081218354404,\n",
       "  109.7984828390181,\n",
       "  112.96497997175902,\n",
       "  90.35677300393581,\n",
       "  104.55255057383329,\n",
       "  88.36987936962396,\n",
       "  71.06509739160538],\n",
       " 'test_loss': [74.31425428390503,\n",
       "  55.85645855218172,\n",
       "  50.78810288012028,\n",
       "  48.93907452374697,\n",
       "  121.8038381934166,\n",
       "  47.889462150633335,\n",
       "  43.95853876322508,\n",
       "  45.37250925600529,\n",
       "  42.174229480326176,\n",
       "  48.53823448717594,\n",
       "  69.85238799452782,\n",
       "  45.52999860048294,\n",
       "  42.21219501644373,\n",
       "  46.21113395690918,\n",
       "  43.42906827479601,\n",
       "  44.28614668548107,\n",
       "  40.69530634582043,\n",
       "  42.30843772739172,\n",
       "  43.56898867338896,\n",
       "  42.658156000077724,\n",
       "  38.679468624293804,\n",
       "  40.49032638221979,\n",
       "  44.5439650118351,\n",
       "  43.132219702005386,\n",
       "  48.18362686783075,\n",
       "  42.61178895831108,\n",
       "  44.79326942563057,\n",
       "  46.90752314776182,\n",
       "  47.36696935072541,\n",
       "  51.72065329551697],\n",
       " 'train_accuracy': [80.10833333333333,\n",
       "  86.75166666666667,\n",
       "  88.285,\n",
       "  88.43833333333333,\n",
       "  89.39166666666667,\n",
       "  88.45333333333333,\n",
       "  89.98166666666667,\n",
       "  91.29166666666667,\n",
       "  91.685,\n",
       "  91.42,\n",
       "  89.8,\n",
       "  88.81666666666666,\n",
       "  91.59,\n",
       "  90.39500000000001,\n",
       "  88.98833333333333,\n",
       "  91.36833333333333,\n",
       "  92.38499999999999,\n",
       "  93.11666666666667,\n",
       "  92.54833333333333,\n",
       "  93.08999999999999,\n",
       "  94.11,\n",
       "  94.36666666666666,\n",
       "  94.845,\n",
       "  95.17333333333333,\n",
       "  95.555,\n",
       "  95.69,\n",
       "  96.41833333333332,\n",
       "  95.96833333333333,\n",
       "  96.575,\n",
       "  97.20166666666667],\n",
       " 'test_accuracy': [82.61,\n",
       "  86.92,\n",
       "  88.13,\n",
       "  88.71,\n",
       "  76.57000000000001,\n",
       "  88.75,\n",
       "  89.72,\n",
       "  89.42,\n",
       "  90.25999999999999,\n",
       "  88.77000000000001,\n",
       "  83.73,\n",
       "  89.73,\n",
       "  90.36,\n",
       "  89.11,\n",
       "  89.79,\n",
       "  89.92999999999999,\n",
       "  90.99000000000001,\n",
       "  90.55,\n",
       "  90.11,\n",
       "  90.67,\n",
       "  90.99000000000001,\n",
       "  91.14999999999999,\n",
       "  90.75,\n",
       "  90.57,\n",
       "  90.63,\n",
       "  91.24,\n",
       "  91.39,\n",
       "  90.74,\n",
       "  91.58,\n",
       "  90.97]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train resnet model (this part can take a while, so run this trainer using CUDA (torch.cuda())!)\n",
    "results = trainer.run_dl_model(trainloader, testloader, resnet_model, resnet_optimizer, resnet_loss_function, resnet_epochs)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5b984926316d402ca5cc522131f70e2b",
    "deepnote_cell_height": 74.78125,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "62793d04-d528-4115-8ac3-ef1aa25c3727",
    "tags": []
   },
   "source": [
    "Feel free to play around with parameters for optimizer, loss function, epochs for resnet and basic CNN model. For basic CNN model, you can play around with the layer parameters and architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8488eaf2-ff92-4a43-b350-fdb8e01ce644' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "d853a93e3911421692c2afc5b062ba42",
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
